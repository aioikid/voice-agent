import { useState, useEffect, useCallback, useRef } from 'react';
import { Room, RoomEvent, Track, RemoteTrack, createLocalAudioTrack } from 'livekit-client';
import { VoiceAgentState, LiveKitConfig } from '../types';

export const useLiveKitVoiceAgent = (config: LiveKitConfig) => {
  const [state, setState] = useState<VoiceAgentState>({
    isConnected: false,
    isConnecting: false,
    isMuted: false,
    isListening: false,
    audioLevel: 0,
    error: null,
  });

  const roomRef = useRef<Room | null>(null);
  const audioLevelInterval = useRef<NodeJS.Timeout | null>(null);

  const updateAudioLevel = useCallback(() => {
    if (!roomRef.current) return;

    const localTrack = roomRef.current.localParticipant.audioTrackPublications.values().next().value?.track;
    if (localTrack && localTrack.kind === Track.Kind.Audio) {
      const level = localTrack.getAudioLevel();
      setState(prev => ({ ...prev, audioLevel: level }));
    }
  }, []);

  const connect = useCallback(async () => {
    if (!config.url || !config.token) {
      setState(prev => ({ ...prev, error: 'Missing configuration' }));
      return;
    }

    setState(prev => ({ ...prev, isConnecting: true, error: null }));

    try {
      const room = new Room();
      roomRef.current = room;

      room.on(RoomEvent.Connected, () => {
        console.log('Room connected successfully');
        setState(prev => ({ ...prev, isConnected: true, isConnecting: false }));
        audioLevelInterval.current = setInterval(updateAudioLevel, 100);
        enableMicrophone(room);
      });

      room.on(RoomEvent.Disconnected, () => {
        console.log('Room disconnected');
        setState(prev => ({ 
          ...prev, 
          isConnected: false, 
          isConnecting: false,
          isListening: false
        }));
        
        if (audioLevelInterval.current) {
          clearInterval(audioLevelInterval.current);
          audioLevelInterval.current = null;
        }
      });

      room.on(RoomEvent.TrackSubscribed, (track: RemoteTrack) => {
        console.log('Track subscribed:', track.kind);
        if (track.kind === Track.Kind.Audio) {
          setState(prev => ({ ...prev, isListening: true }));
          const audioElement = track.attach();
          if (audioElement) {
            audioElement.autoplay = true;
            audioElement.volume = 1.0;
            document.body.appendChild(audioElement);
            console.log('Audio element attached and playing');
          }
        }
      });

      room.on(RoomEvent.TrackUnsubscribed, (track: RemoteTrack) => {
        console.log('Track unsubscribed:', track.kind);
        if (track.kind === Track.Kind.Audio) {
          setState(prev => ({ ...prev, isListening: false }));
          const audioElements = document.querySelectorAll('audio');
          audioElements.forEach(element => {
            if (element.srcObject === track.mediaStream) {
              element.remove();
            }
          });
        }
      });

      console.log('Connecting to room...');
      await room.connect(config.url, config.token);
      
    } catch (error) {
      console.error('Failed to connect:', error);
      setState(prev => ({ 
        ...prev, 
        isConnecting: false, 
        error: error instanceof Error ? error.message : 'Connection failed'
      }));
    }
  }, [config, updateAudioLevel]);

  const enableMicrophone = useCallback(async (room: Room) => {
    try {
      console.log('=== éŸ³å£°å°‚ç”¨ãƒžã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹é–‹å§‹ ===');
      console.log('Navigator.mediaDevices available:', !!navigator.mediaDevices);
      console.log('getUserMedia available:', !!navigator.mediaDevices?.getUserMedia);
      console.log('Current URL:', window.location.href);
      console.log('Is secure context:', window.isSecureContext);
      
      if (!navigator.mediaDevices?.getUserMedia) {
        throw new Error('getUserMedia is not supported in this browser');
      }

      // ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§ã‚’å–å¾—
      const devices = await navigator.mediaDevices.enumerateDevices();
      const audioInputs = devices.filter(device => device.kind === 'audioinput');
      console.log('Available audio input devices:', audioInputs.length);
      console.log('Audio devices:', audioInputs.map(device => ({
        deviceId: device.deviceId,
        label: device.label,
        groupId: device.groupId
      })));
      
      if (audioInputs.length === 0) {
        throw new Error('No audio input devices found');
      }

      // æ¨©é™çŠ¶æ…‹ã‚’ç¢ºèª
      try {
        const permission = await navigator.permissions.query({ name: 'microphone' as PermissionName });
        console.log('Microphone permission state:', permission.state);
      } catch (permError) {
        console.log('Permission query not supported:', permError);
      }

      // æ–¹æ³•1: createLocalAudioTrackã‚’ä½¿ç”¨ï¼ˆéŸ³å£°å°‚ç”¨ï¼‰
      console.log('=== æ–¹æ³•1: createLocalAudioTrackä½¿ç”¨ ===');
      try {
        console.log('Creating local audio track...');
        const audioTrack = await createLocalAudioTrack({
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true,
        });
        
        console.log('Audio track created successfully:', {
          label: audioTrack.mediaStreamTrack.label,
          deviceId: audioTrack.mediaStreamTrack.getSettings().deviceId,
          enabled: audioTrack.mediaStreamTrack.enabled,
          muted: audioTrack.mediaStreamTrack.muted,
          readyState: audioTrack.mediaStreamTrack.readyState
        });

        // ãƒˆãƒ©ãƒƒã‚¯ã‚’ãƒ«ãƒ¼ãƒ ã«å…¬é–‹
        console.log('Publishing audio track to room...');
        await room.localParticipant.publishTrack(audioTrack);
        console.log('Audio track published successfully');
        
        return; // æˆåŠŸã—ãŸã®ã§çµ‚äº†
        
      } catch (trackError) {
        console.error('createLocalAudioTrack failed:', trackError);
      }

      // æ–¹æ³•2: getUserMediaã§ç›´æŽ¥éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å–å¾—
      console.log('=== æ–¹æ³•2: getUserMediaç›´æŽ¥ä½¿ç”¨ ===');
      try {
        console.log('Getting user media (audio only)...');
        const stream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          },
          video: false // æ˜Žç¤ºçš„ã«ãƒ“ãƒ‡ã‚ªã‚’ç„¡åŠ¹åŒ–
        });
        
        console.log('Audio stream obtained:', stream);
        const audioTracks = stream.getAudioTracks();
        console.log('Audio tracks in stream:', audioTracks.length);
        
        if (audioTracks.length > 0) {
          const track = audioTracks[0];
          console.log('Audio track details:', {
            label: track.label,
            deviceId: track.getSettings().deviceId,
            enabled: track.enabled,
            muted: track.muted,
            readyState: track.readyState,
            settings: track.getSettings()
          });

          // LiveKitã®LocalAudioTrackã‚’ä½œæˆ
          const { LocalAudioTrack } = await import('livekit-client');
          const localAudioTrack = new LocalAudioTrack(track);
          
          console.log('Publishing manual audio track...');
          await room.localParticipant.publishTrack(localAudioTrack);
          console.log('Manual audio track published successfully');
          
          return; // æˆåŠŸã—ãŸã®ã§çµ‚äº†
        }
        
      } catch (streamError) {
        console.error('getUserMedia failed:', streamError);
      }

      // æ–¹æ³•3: æœ€å¾Œã®æ‰‹æ®µ - enableCameraAndMicrophoneï¼ˆãŸã ã—éŸ³å£°ã®ã¿ï¼‰
      console.log('=== æ–¹æ³•3: enableCameraAndMicrophoneï¼ˆéŸ³å£°ã®ã¿ï¼‰===');
      try {
        console.log('Using enableCameraAndMicrophone with audio only...');
        await room.localParticipant.enableCameraAndMicrophone(false, true);
        console.log('enableCameraAndMicrophone succeeded');
        return;
        
      } catch (enableError) {
        console.error('enableCameraAndMicrophone failed:', enableError);
        throw enableError;
      }
      
    } catch (error) {
      console.error('=== å…¨ã¦ã®éŸ³å£°ã‚¢ã‚¯ã‚»ã‚¹æ–¹æ³•ãŒå¤±æ•— ===');
      console.error('Final error:', error);
      
      if (error instanceof Error) {
        if (error.name === 'NotAllowedError') {
          setState(prev => ({ 
            ...prev, 
            error: 'ãƒžã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®ã‚¢ãƒ‰ãƒ¬ã‚¹ãƒãƒ¼å·¦å´ã®ðŸ”’ãƒžãƒ¼ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€ãƒžã‚¤ã‚¯ã‚’ã€Œè¨±å¯ã€ã«è¨­å®šã—ã¦ãã ã•ã„ã€‚' 
          }));
        } else if (error.name === 'NotFoundError') {
          setState(prev => ({ 
            ...prev, 
            error: 'ãƒžã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚·ã‚¹ãƒ†ãƒ ã®ãƒžã‚¤ã‚¯è¨­å®šã¨ãƒ‡ãƒã‚¤ã‚¹ãƒžãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚' 
          }));
        } else if (error.name === 'NotReadableError') {
          setState(prev => ({ 
            ...prev, 
            error: 'ãƒžã‚¤ã‚¯ãŒä»–ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆZoomã€Teamsã€Discordç­‰ï¼‰ã§ä½¿ç”¨ä¸­ã§ã™ã€‚ä»–ã®ã‚¢ãƒ—ãƒªã‚’å®Œå…¨ã«çµ‚äº†ã—ã¦ãƒ–ãƒ©ã‚¦ã‚¶ã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„ã€‚' 
          }));
        } else if (error.name === 'OverconstrainedError') {
          setState(prev => ({ 
            ...prev, 
            error: 'ãƒžã‚¤ã‚¯ã®åˆ¶ç´„è¨­å®šã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ã®ãƒžã‚¤ã‚¯è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚' 
          }));
        } else {
          setState(prev => ({ 
            ...prev, 
            error: `ãƒžã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼ (${error.name}): ${error.message}` 
          }));
        }
      } else {
        setState(prev => ({ 
          ...prev, 
          error: 'ãƒžã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã‚’å†èµ·å‹•ã—ã¦ãŠè©¦ã—ãã ã•ã„ã€‚' 
        }));
      }
    }
  }, []);

  const disconnect = useCallback(() => {
    console.log('Disconnecting from room...');
    if (roomRef.current) {
      roomRef.current.disconnect();
      roomRef.current = null;
    }
    
    if (audioLevelInterval.current) {
      clearInterval(audioLevelInterval.current);
      audioLevelInterval.current = null;
    }
  }, []);

  const toggleMute = useCallback(() => {
    if (roomRef.current) {
      const audioTrack = roomRef.current.localParticipant.audioTrackPublications.values().next().value?.track;
      if (audioTrack) {
        const newMutedState = !audioTrack.isMuted;
        audioTrack.setMuted(newMutedState);
        setState(prev => ({ ...prev, isMuted: newMutedState }));
        console.log('Microphone muted:', newMutedState);
      }
    }
  }, []);

  useEffect(() => {
    return () => {
      disconnect();
    };
  }, [disconnect]);

  return {
    state,
    connect,
    disconnect,
    toggleMute,
  };
};